{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab89d299",
   "metadata": {},
   "source": [
    "# EXP4 — HMM POS Tagging (with Transition & Emission Matrices)\n",
    "\n",
    "**This notebook is an edited version of `EXP4_HMM_POS_LOCAL.ipynb` that adds cells to extract, label, and save the HMM transition and emission matrices.**\n",
    "\n",
    "**How to use:** run all cells in order. The HMM is trained unsupervised on your local Gujarati corpus and the notebook prints and saves the following:\n",
    "- start probabilities (startprob_)\n",
    "- transition matrix (transmat_) with states labelled S0..S{n}\n",
    "- emission matrix (emissionprob_) with columns labelled by top vocabulary tokens\n",
    "\n",
    "Generated: 2025-10-30T09:06:40.432919"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "672f7acc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports ready\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!pip install -q nltk hmmlearn pandas numpy\n",
    "\n",
    "import os, sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from hmmlearn import hmm\n",
    "\n",
    "nltk.download('punkt', quiet=True)\n",
    "print(\"Imports ready\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4961f17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded characters: 3461251\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Local corpus path - edit if needed\n",
    "corpus_dir = r\"X:/DJ Sanghvi/sem 7/nlp/NLP_LAB_GYANGUJ/data/next\"\n",
    "\n",
    "texts = []\n",
    "for fn in os.listdir(corpus_dir):\n",
    "    if fn.endswith('.txt'):\n",
    "        with open(os.path.join(corpus_dir, fn), 'r', encoding='utf-8') as f:\n",
    "            texts.append(f.read())\n",
    "\n",
    "corpus = \" \".join(texts)\n",
    "print(\"Loaded characters:\", len(corpus))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a938097c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total tokens: 507737\n",
      "Vocab size: 60194\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Tokenize (simple whitespace splitting) - adapt tokenization if needed\n",
    "tokens = []\n",
    "for part in nltk.tokenize.sent_tokenize(corpus):\n",
    "    for t in part.split():\n",
    "        if t.strip():\n",
    "            tokens.append(t.strip())\n",
    "\n",
    "print(\"Total tokens:\", len(tokens))\n",
    "# build vocab\n",
    "vocab = sorted(list(set(tokens)))\n",
    "word_to_id = {w:i for i,w in enumerate(vocab)}\n",
    "id_to_word = {i:w for w,i in word_to_id.items()}\n",
    "print(\"Vocab size:\", len(vocab))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "607325e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultinomialHMM has undergone major changes. The previous version was implementing a CategoricalHMM (a special case of MultinomialHMM). This new implementation follows the standard definition for a Multinomial distribution (e.g. as in https://en.wikipedia.org/wiki/Multinomial_distribution). See these issues for details:\n",
      "https://github.com/hmmlearn/hmmlearn/issues/335\n",
      "https://github.com/hmmlearn/hmmlearn/issues/340\n",
      "         1       0.00000000             +nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HMM trained: n_states = 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "         2       0.00000000      +0.00000000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Encode tokens as integer symbol IDs\n",
    "import numpy as np\n",
    "X = np.array([word_to_id[w] for w in tokens]).reshape(-1,1)\n",
    "\n",
    "# Train unsupervised Multinomial HMM\n",
    "n_states = 4  # adjust if desired\n",
    "model = hmm.MultinomialHMM(n_components=n_states, n_iter=30, verbose=True, random_state=42)\n",
    "model.fit(X)\n",
    "\n",
    "print(\"HMM trained: n_states =\", n_states)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "69e556da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 30 decoded tokens and states:\n",
      "જીવવિજ્ઞાન           -> S1\n",
      "ધોરણ                 -> S2\n",
      "ઉઠે                  -> S2\n",
      "પ્રતિજ્ઞાપત્ર        -> S2\n",
      "ભારત                 -> S2\n",
      "મારો                 -> S2\n",
      "દેશ                  -> S2\n",
      "બધાં                 -> S2\n",
      "ભારતીયો              -> S2\n",
      "મારા                 -> S2\n",
      "ભાઈબહેન              -> S2\n",
      "મારા                 -> S2\n",
      "દેશને                -> S2\n",
      "ચાહું                -> S2\n",
      "છું                  -> S2\n",
      "તેના                 -> S2\n",
      "સમૃદ્ધ               -> S2\n",
      "વૈવિધ્યપૂર્ણ         -> S2\n",
      "વારસાનો              -> S2\n",
      "મને                  -> S2\n",
      "ગર્વ                 -> S2\n",
      "સદાય                 -> S2\n",
      "તેને                 -> S2\n",
      "લાયક                 -> S2\n",
      "બનવા                 -> S2\n",
      "પ્રયત્ત              -> S2\n",
      "કરીશ                 -> S2\n",
      "મારાં                -> S2\n",
      "માતાપિતા,            -> S2\n",
      "શિક્ષકો              -> S2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\omtan\\AppData\\Local\\Temp\\ipykernel_26032\\40054505.py:3: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  decoded = [(id_to_word[int(X[i])], int(states[i])) for i in range(min(100, len(states)))]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Decode a short prefix to show state sequence\n",
    "logprob, states = model.decode(X[:100], algorithm='viterbi')\n",
    "decoded = [(id_to_word[int(X[i])], int(states[i])) for i in range(min(100, len(states)))]\n",
    "print(\"First 30 decoded tokens and states:\")\n",
    "for w,s in decoded[:30]:\n",
    "    print(f\"{w:20s} -> S{s}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b18c9ce9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "startprob_ shape: (4,)\n",
      "transmat_ shape: (4, 4)\n",
      "emissionprob_ shape: (4, 1)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Extract HMM matrices\n",
    "start_prob = model.startprob_        # shape (n_states,)\n",
    "trans_mat = model.transmat_          # shape (n_states, n_states)\n",
    "emission_mat = model.emissionprob_   # shape (n_states, n_symbols)\n",
    "\n",
    "print(\"startprob_ shape:\", start_prob.shape)\n",
    "print(\"transmat_ shape:\", trans_mat.shape)\n",
    "print(\"emissionprob_ shape:\", emission_mat.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5d977c79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transition matrix (rows: from-state, cols: to-state):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>S0</th>\n",
       "      <th>S1</th>\n",
       "      <th>S2</th>\n",
       "      <th>S3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>S0</th>\n",
       "      <td>0.1997</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.7986</td>\n",
       "      <td>0.0017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S1</th>\n",
       "      <td>0.0449</td>\n",
       "      <td>0.1824</td>\n",
       "      <td>0.7345</td>\n",
       "      <td>0.0382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S2</th>\n",
       "      <td>0.2389</td>\n",
       "      <td>0.0088</td>\n",
       "      <td>0.7522</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S3</th>\n",
       "      <td>0.9136</td>\n",
       "      <td>0.0033</td>\n",
       "      <td>0.0831</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        S0      S1      S2      S3\n",
       "S0  0.1997  0.0000  0.7986  0.0017\n",
       "S1  0.0449  0.1824  0.7345  0.0382\n",
       "S2  0.2389  0.0088  0.7522  0.0001\n",
       "S3  0.9136  0.0033  0.0831  0.0001"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved transition matrix to /exp4_transition_matrix.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create DataFrame for transition matrix with labelled rows/cols\n",
    "state_labels = [f\"S{i}\" for i in range(model.n_components)]\n",
    "df_trans = pd.DataFrame(trans_mat, index=state_labels, columns=state_labels)\n",
    "print(\"Transition matrix (rows: from-state, cols: to-state):\")\n",
    "display(df_trans.round(4))\n",
    "\n",
    "# Save transition matrix\n",
    "df_trans.to_csv('/exp4_transition_matrix.csv', index=True)\n",
    "print(\"\\nSaved transition matrix to /exp4_transition_matrix.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7b2a5b34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "State S0 top 15 emissions:\n",
      "  !                    : 1.00000\n",
      "\n",
      "State S1 top 15 emissions:\n",
      "  !                    : 1.00000\n",
      "\n",
      "State S2 top 15 emissions:\n",
      "  !                    : 1.00000\n",
      "\n",
      "State S3 top 15 emissions:\n",
      "  !                    : 1.00000\n",
      "\n",
      "Saved reduced emission table to /exp4_emission_topk.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# For emission matrix, showing full matrix is large (states x vocab). We'll show top-k emissions per state\n",
    "top_k = 15\n",
    "n_states, n_symbols = emission_mat.shape\n",
    "top_words_per_state = {}\n",
    "\n",
    "for s in range(n_states):\n",
    "    probs = emission_mat[s]  # length n_symbols\n",
    "    top_idx = np.argsort(-probs)[:top_k]\n",
    "    top_words = [(id_to_word[i], float(probs[i])) for i in top_idx]\n",
    "    top_words_per_state[f\"S{s}\"] = top_words\n",
    "\n",
    "# Display top words per state\n",
    "for s, lst in top_words_per_state.items():\n",
    "    print(f\"\\nState {s} top {top_k} emissions:\")\n",
    "    for w,p in lst:\n",
    "        print(f\"  {w:20s} : {p:.5f}\")\n",
    "\n",
    "# Save a reduced emission CSV: rows = states, columns = top_k words (word:prob)\n",
    "rows = []\n",
    "for s, lst in top_words_per_state.items():\n",
    "    row = {'state': s}\n",
    "    for i, (w,p) in enumerate(lst):\n",
    "        row[f\"top{i+1}_word\"] = w\n",
    "        row[f\"top{i+1}_prob\"] = p\n",
    "    rows.append(row)\n",
    "\n",
    "df_emit_reduced = pd.DataFrame(rows)\n",
    "df_emit_reduced.to_csv('/exp4_emission_topk.csv', index=False)\n",
    "print(\"\\nSaved reduced emission table to /exp4_emission_topk.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d92750",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State → POS tag mapping:\n",
      "S1 → NOUN\n",
      "S2 → NOUN\n",
      "\n",
      "✅ Accuracy: 33.33 %\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         AUX       0.00      0.00      0.00         2\n",
      "        NOUN       0.33      1.00      0.50         4\n",
      "        PRON       0.00      0.00      0.00         3\n",
      "        VERB       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.33        12\n",
      "   macro avg       0.08      0.25      0.12        12\n",
      "weighted avg       0.11      0.33      0.17        12\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\omtan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\omtan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\omtan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test_data = [\n",
    "    (\"હું શાળા જાઉં છું\",        [\"PRON\",\"NOUN\",\"VERB\",\"AUX\"]),\n",
    "    (\"તું ઘર આવો\",              [\"PRON\",\"NOUN\",\"VERB\"]),\n",
    "    (\"તે પુસ્તકો વાંચે છે\",      [\"PRON\",\"NOUN\",\"VERB\",\"AUX\"]),\n",
    "    (\"મિત્રો સાથે રમે છે\",      [\"NOUN\",\"ADP\",\"VERB\",\"AUX\"]),\n",
    "    (\"આજે વાતાવરણ સારો છે\",    [\"ADV\",\"NOUN\",\"ADJ\",\"AUX\"]),\n",
    "]\n",
    "\n",
    "\n",
    "gold_words = []\n",
    "gold_tags  = []\n",
    "for sent, tags in test_data:\n",
    "    words = sent.split()\n",
    "    gold_words += words\n",
    "    gold_tags  += tags\n",
    "\n",
    "\n",
    "test_ids = [word_to_id[w] for w in gold_words if w in word_to_id]\n",
    "test_X   = np.array(test_ids).reshape(-1,1)\n",
    "\n",
    "# ---- Predict HMM states ----\n",
    "_, pred_states = model.decode(test_X, algorithm=\"viterbi\")\n",
    "pred_states = list(pred_states)\n",
    "\n",
    "# ---- Map HMM states -> Gold POS tags using majority vote ----\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "state_tag_map = defaultdict(list)\n",
    "idx = 0\n",
    "for w, tag in zip(gold_words, gold_tags):\n",
    "    if w in word_to_id:\n",
    "        state_tag_map[pred_states[idx]].append(tag)\n",
    "        idx += 1\n",
    "\n",
    "final_map = {\n",
    "    state: Counter(tags).most_common(1)[0][0] \n",
    "    for state, tags in state_tag_map.items()\n",
    "}\n",
    "\n",
    "print(\"State → POS tag mapping:\")\n",
    "for st, tg in final_map.items():\n",
    "    print(f\"S{st} → {tg}\")\n",
    "\n",
    "# ---- Convert predicted states to predicted tags ----\n",
    "pred_tags = [final_map[s] for s in pred_states]\n",
    "\n",
    "# ---- Compute accuracy ----\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "print(\"\\n✅ Accuracy:\", round(accuracy_score(gold_tags[:len(pred_tags)], pred_tags) * 100, 2), \"%\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(gold_tags[:len(pred_tags)], pred_tags))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
