{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96078d35",
   "metadata": {},
   "source": [
    "# Fixed: Rule-based Gujarati Morphological Segmentation\n",
    "**What this notebook does (high-success, common-suffix rules):**\n",
    "\n",
    "- Loads local `.txt` files from a folder you specify\n",
    "- Normalizes and tokenizes Gujarati text\n",
    "- Applies a compact list of **common Gujarati suffixes** (locative, instrumental, plural, case markers) to split **stem + suffix**\n",
    "- Shows demo outputs and corpus samples\n",
    "\n",
    "**How to use:** Edit the `corpus_dir` variable in the \"Load corpus\" cell to point at your local folder containing `.txt` files and run all cells.\n",
    "\n",
    "Generated on: 2025-10-29T18:57:19.534827\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4357c80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import unicodedata\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "def normalize_text(s):\n",
    "    return unicodedata.normalize('NFC', s).strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "996891e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 8 files from X:/DJ Sanghvi/sem 7/nlp/NLP_LAB_GYANGUJ/data/next\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File</th>\n",
       "      <th>Content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>class11_biology_prepro.txt</td>\n",
       "      <td>જીવવિજ્ઞાન ધોરણ ઉઠે પ્રતિજ્ઞાપત્ર ભારત મારો દે...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>class11_chemistry_prepro.txt</td>\n",
       "      <td>પરમાણુનો ક્વોન્ટમ યાંત્રિકીય નમૂનો તત્ત્વોનું ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>class11_maths_prepro.txt</td>\n",
       "      <td>પ્રકરણમાં આપણે ગણ સંબંધિત પાયાની વ્યાખ્યાઓ ગણ ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           File  \\\n",
       "0    class11_biology_prepro.txt   \n",
       "1  class11_chemistry_prepro.txt   \n",
       "2      class11_maths_prepro.txt   \n",
       "\n",
       "                                             Content  \n",
       "0  જીવવિજ્ઞાન ધોરણ ઉઠે પ્રતિજ્ઞાપત્ર ભારત મારો દે...  \n",
       "1  પરમાણુનો ક્વોન્ટમ યાંત્રિકીય નમૂનો તત્ત્વોનું ...  \n",
       "2  પ્રકરણમાં આપણે ગણ સંબંધિત પાયાની વ્યાખ્યાઓ ગણ ...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- USER: set this to your local path ---\n",
    "corpus_dir = r\"X:/DJ Sanghvi/sem 7/nlp/NLP_LAB_GYANGUJ/data/next\"\n",
    "# ----------------------------------------\n",
    "\n",
    "texts = []\n",
    "for fn in os.listdir(corpus_dir):\n",
    "    if fn.endswith('.txt'):\n",
    "        path = os.path.join(corpus_dir, fn)\n",
    "        with open(path, 'r', encoding='utf-8') as f:\n",
    "            txt = f.read().strip()\n",
    "            if txt:\n",
    "                texts.append((fn, normalize_text(txt)))\n",
    "\n",
    "if not texts:\n",
    "    print('No .txt files found in', corpus_dir)\n",
    "else:\n",
    "    print(f'Loaded {len(texts)} files from', corpus_dir)\n",
    "\n",
    "df_files = pd.DataFrame(texts, columns=['File', 'Content'])\n",
    "df_files.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da175ca4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total tokens (approx): 507730\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>જીવવિજ્ઞાન</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ધોરણ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ઉઠે</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>પ્રતિજ્ઞાપત્ર</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ભારત</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>મારો</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>દેશ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>બધાં</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ભારતીયો</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>મારા</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Word\n",
       "0     જીવવિજ્ઞાન\n",
       "1           ધોરણ\n",
       "2            ઉઠે\n",
       "3  પ્રતિજ્ઞાપત્ર\n",
       "4           ભારત\n",
       "5           મારો\n",
       "6            દેશ\n",
       "7           બધાં\n",
       "8        ભારતીયો\n",
       "9           મારા"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = []\n",
    "for fn, txt in texts:\n",
    "    tokens = [t for t in txt.split() if t]\n",
    "    words.extend(tokens)\n",
    "\n",
    "print('Total tokens (approx):', len(words))\n",
    "sample_words = words[:2000]\n",
    "df = pd.DataFrame({'Word': sample_words})\n",
    "df.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "727993c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "શિક્ષકો -> stem:'શિક્ષક'  suffix:'ો'\n",
      "સરકારમાં -> stem:'સરકાર'  suffix:'માં'\n",
      "મિત્રોથી -> stem:'મિત્રો'  suffix:'થી'\n",
      "કલાકો -> stem:'કલાક'  suffix:'ો'\n",
      "શેરબજારો -> stem:'શેરબજાર'  suffix:'ો'\n"
     ]
    }
   ],
   "source": [
    "common_suffixes = [\n",
    "    'માં','માંથી','ઓમાં','ઓને','ઓના','ઓથી',\n",
    "    'થી','ને','ના','માં','નું','ની','ઓ','ે','ો'\n",
    "]\n",
    "common_suffixes = sorted(set([normalize_text(s) for s in common_suffixes if s.strip()]), key=len, reverse=True)\n",
    "\n",
    "def extract_stem_rule(word, suffix_list=common_suffixes):\n",
    "    w = normalize_text(word)\n",
    "    for suf in suffix_list:\n",
    "        if len(suf) == 0:\n",
    "            continue\n",
    "        if w.endswith(suf):\n",
    "            stem = w[:-len(suf)]\n",
    "            if stem == '':\n",
    "                return w, suf\n",
    "            return stem, suf\n",
    "    return w, ''\n",
    "\n",
    "examples = ['શિક્ષકો', 'સરકારમાં', 'મિત્રોથી', 'કલાકો', 'શેરબજારો']\n",
    "for ex in examples:\n",
    "    stem, suf = extract_stem_rule(ex)\n",
    "    print(f\"{ex} -> stem:'{stem}'  suffix:'{suf}'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "128a19a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Of first 200 tokens, 41 (20.50%) had a matched suffix from the common list\n",
      "\n",
      "Top suffixes in sample:\n",
      "Suffix\n",
      "       159\n",
      "ો       10\n",
      "ને      10\n",
      "ે        8\n",
      "ના       6\n",
      "માં      4\n",
      "ની       2\n",
      "થી       1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "N = 200\n",
    "results = []\n",
    "for w in sample_words[:N]:\n",
    "    stem, suf = extract_stem_rule(w)\n",
    "    results.append((w, stem, suf))\n",
    "\n",
    "df_seg = pd.DataFrame(results, columns=['Word', 'Stem', 'Suffix'])\n",
    "df_seg.head(30)\n",
    "\n",
    "non_empty = df_seg['Suffix'].apply(lambda x: bool(x)).sum()\n",
    "print(f\"Of first {N} tokens, {non_empty} ({non_empty/N:.2%}) had a matched suffix from the common list\")\n",
    "\n",
    "print('\\nTop suffixes in sample:')\n",
    "print(df_seg['Suffix'].value_counts().head(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b035dd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "શિક્ષકો         -> stem: 'શિક્ષક      ' | suffix: 'ો'\n",
      "સરકારે          -> stem: 'સરકાર       ' | suffix: 'ે'\n",
      "મિત્રોથી        -> stem: 'મિત્રો      ' | suffix: 'થી'\n",
      "કલાકો           -> stem: 'કલાક        ' | suffix: 'ો'\n",
      "શેરબજારો        -> stem: 'શેરબજાર     ' | suffix: 'ો'\n",
      "વિદ્યાર્થીઓ     -> stem: 'વિદ્યાર્થી  ' | suffix: 'ઓ'\n",
      "ગામોમાં         -> stem: 'ગામો        ' | suffix: 'માં'\n",
      "શાળામાં         -> stem: 'શાળા        ' | suffix: 'માં'\n",
      "અધ્યાપકો        -> stem: 'અધ્યાપક     ' | suffix: 'ો'\n",
      "વિજ્ઞાનીઓ       -> stem: 'વિજ્ઞાની    ' | suffix: 'ઓ'\n",
      "પુસ્તકોમાં      -> stem: 'પુસ્તકો     ' | suffix: 'માં'\n",
      "પત્રકારો        -> stem: 'પત્રકાર     ' | suffix: 'ો'\n",
      "રોગોથી          -> stem: 'રોગો        ' | suffix: 'થી'\n",
      "કામદારો         -> stem: 'કામદાર      ' | suffix: 'ો'\n",
      "શિક્ષણમાં       -> stem: 'શિક્ષણ      ' | suffix: 'માં'\n",
      "વૃક્ષો          -> stem: 'વૃક્ષ       ' | suffix: 'ો'\n",
      "બાળકોએ          -> stem: 'બાળકોએ      ' | suffix: ''\n",
      "રમતોમાં         -> stem: 'રમતો        ' | suffix: 'માં'\n",
      "મિત્રતામાં      -> stem: 'મિત્રતા     ' | suffix: 'માં'\n",
      "વિદ્યાપીઠો      -> stem: 'વિદ્યાપીઠ   ' | suffix: 'ો'\n",
      "પ્રયત્નોથી      -> stem: 'પ્રયત્નો    ' | suffix: 'થી'\n",
      "સમયોએ           -> stem: 'સમયોએ       ' | suffix: ''\n",
      "નાગરિકોએ        -> stem: 'નાગરિકોએ    ' | suffix: ''\n",
      "આશાઓથી          -> stem: 'આશા         ' | suffix: 'ઓથી'\n",
      "વિચારધારાઓ      -> stem: 'વિચારધારા   ' | suffix: 'ઓ'\n"
     ]
    }
   ],
   "source": [
    "demo_words = [\n",
    "    'શિક્ષકો','સરકારે','મિત્રોથી','કલાકો','શેરબજારો',\n",
    "    'વિદ્યાર્થીઓ','ગામોમાં','શાળામાં','અધ્યાપકો','વિજ્ઞાનીઓ',\n",
    "    'પુસ્તકોમાં','પત્રકારો','રોગોથી','કામદારો','શિક્ષણમાં',\n",
    "    'વૃક્ષો','બાળકોએ','રમતોમાં','મિત્રતામાં','વિદ્યાપીઠો',\n",
    "    'પ્રયત્નોથી','સમયોએ','નાગરિકોએ','આશાઓથી','વિચારધારાઓ'\n",
    "]\n",
    "\n",
    "for w in demo_words:\n",
    "    stem, suf = extract_stem_rule(w)\n",
    "    print(f\"{w:15s} -> stem: '{stem:12s}' | suffix: '{suf}'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "faedf631",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Compatibility demos:\n",
      "('કલાક', 'ો')\n",
      "('કલાક', 'ો')\n"
     ]
    }
   ],
   "source": [
    "def extract_stem_from_label_compat(word, label=None):\n",
    "    try:\n",
    "        if label and '1' in str(label):\n",
    "            lab = str(label)\n",
    "            pos = lab.index('1')\n",
    "            stem = word[:pos+1]\n",
    "            suffix = word[pos+1:]\n",
    "            return stem, suffix\n",
    "    except Exception:\n",
    "        pass\n",
    "    return extract_stem_rule(word)\n",
    "\n",
    "print('\\nCompatibility demos:')\n",
    "print(extract_stem_from_label_compat('કલાકો', '00010'))\n",
    "print(extract_stem_from_label_compat('કલાકો', '00000'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9315898c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved segmented sample to temp.csv\n"
     ]
    }
   ],
   "source": [
    "out_csv = 'temp6.csv'\n",
    "df_seg.to_csv(out_csv, index=False)\n",
    "print('Saved segmented sample to', out_csv)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
