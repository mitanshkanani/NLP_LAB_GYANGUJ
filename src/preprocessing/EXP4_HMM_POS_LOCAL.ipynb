{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "343148c6",
   "metadata": {},
   "source": [
    "# Experiment 4 — POS Tagging using HMM on Local Gujarati Corpus\n",
    "**Objective:** Perform POS tagging using Hidden Markov Model (HMM) on Gujarati local corpus, compare with rule-based tagging, and evaluate accuracy.\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a58f154",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\omtan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "!pip install -q nltk hmmlearn pandas\n",
    "\n",
    "import nltk, os, pandas as pd, numpy as np\n",
    "from hmmlearn import hmm\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "nltk.download('punkt')\n",
    "\n",
    "corpus_dir = r\"X:/DJ Sanghvi/sem 7/nlp/NLP_LAB_GYANGUJ/data/next\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da93bedd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded characters: 3461251\n"
     ]
    }
   ],
   "source": [
    "texts = []\n",
    "for file in os.listdir(corpus_dir):\n",
    "    if file.endswith(\".txt\"):\n",
    "        with open(os.path.join(corpus_dir, file), 'r', encoding='utf-8') as f:\n",
    "            texts.append(f.read())\n",
    "\n",
    "corpus = \" \".join(texts)\n",
    "print(\"Loaded characters:\", len(corpus))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "161e6ab2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count: 550517\n",
      "['જીવવિજ્ઞાન', 'ધોરણ', 'ઉઠે', 'પ્રતિજ્ઞાપત્ર', 'ભારત', 'મારો', 'દેશ', 'બધાં', 'ભારતીયો', 'મારા', 'ભાઈબહેન', 'મારા', 'દેશને', 'ચાહું', 'છું', 'તેના', 'સમૃદ્ધ', 'વૈવિધ્યપૂર્ણ', 'વારસાનો', 'મને']\n"
     ]
    }
   ],
   "source": [
    "tokens = nltk.word_tokenize(corpus)\n",
    "tokens = [t for t in tokens if t.strip()]\n",
    "print(\"Token count:\", len(tokens))\n",
    "print(tokens[:20])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a72dbf15",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = list(set(tokens))\n",
    "word_to_id = {w:i for i,w in enumerate(vocab)}\n",
    "id_to_word = {i:w for w,i in word_to_id.items()}\n",
    "\n",
    "encoded = np.array([word_to_id[w] for w in tokens]).reshape(-1,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "989cf783",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultinomialHMM has undergone major changes. The previous version was implementing a CategoricalHMM (a special case of MultinomialHMM). This new implementation follows the standard definition for a Multinomial distribution (e.g. as in https://en.wikipedia.org/wiki/Multinomial_distribution). See these issues for details:\n",
      "https://github.com/hmmlearn/hmmlearn/issues/335\n",
      "https://github.com/hmmlearn/hmmlearn/issues/340\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HMM Training Complete ✅\n"
     ]
    }
   ],
   "source": [
    "n_states = 8  # POS-like clusters\n",
    "\n",
    "model = hmm.MultinomialHMM(n_components=n_states, n_iter=20, verbose=False)\n",
    "model.fit(encoded)\n",
    "\n",
    "print(\"HMM Training Complete ✅\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "95982434",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "જીવવિજ્ઞાન TAG6\n",
      "ધોરણ TAG7\n",
      "ઉઠે TAG6\n",
      "પ્રતિજ્ઞાપત્ર TAG7\n",
      "ભારત TAG6\n",
      "મારો TAG7\n",
      "દેશ TAG6\n",
      "બધાં TAG7\n",
      "ભારતીયો TAG6\n",
      "મારા TAG7\n",
      "ભાઈબહેન TAG6\n",
      "મારા TAG7\n",
      "દેશને TAG6\n",
      "ચાહું TAG7\n",
      "છું TAG6\n",
      "તેના TAG7\n",
      "સમૃદ્ધ TAG6\n",
      "વૈવિધ્યપૂર્ણ TAG7\n",
      "વારસાનો TAG6\n",
      "મને TAG7\n"
     ]
    }
   ],
   "source": [
    "logprob, states = model.decode(encoded[:50], algorithm=\"viterbi\")\n",
    "\n",
    "tagged_output = [(id_to_word[encoded[i][0]], f\"TAG{states[i]}\") for i in range(len(states))]\n",
    "for w,t in tagged_output[:20]:\n",
    "    print(w, t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c8689fba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('હું', 'PRON'), ('શાળા', 'NOUN'), ('જાઉં', 'VERB'), ('છું', 'AUX')]\n"
     ]
    }
   ],
   "source": [
    "guj_dict = {\n",
    "    \"હું\":\"PRON\",\"તું\":\"PRON\",\"એ\":\"PRON\",\"તમે\":\"PRON\",\n",
    "    \"છું\":\"AUX\",\"છે\":\"AUX\",\"હતું\":\"AUX\",\"હતા\":\"AUX\",\n",
    "    \"જાઉં\":\"VERB\",\"કરું\":\"VERB\",\"ખાઉં\":\"VERB\",\"આવો\":\"VERB\",\n",
    "    \"શાળા\":\"NOUN\",\"માનવ\":\"NOUN\",\"મિત્ર\":\"NOUN\",\"ઘર\":\"NOUN\",\n",
    "}\n",
    "\n",
    "def rule_tag_sentence(sentence):\n",
    "    words = nltk.word_tokenize(sentence)\n",
    "    return [(w, guj_dict.get(w,\"UNK\")) for w in words]\n",
    "\n",
    "print(rule_tag_sentence(\"હું શાળા જાઉં છું\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f2eee4af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True: ['PRON', 'NOUN', 'VERB', 'AUX', 'PRON', 'NOUN', 'VERB', 'DET', 'PRON', 'NOUN', 'AUX', 'NOUN', 'ADV', 'VERB', 'AUX', 'PRON', 'NOUN', 'VERB', 'AUX']\n",
      "Pred: ['PRON', 'NOUN', 'VERB', 'AUX', 'PRON', 'NOUN', 'VERB', 'UNK', 'UNK', 'NOUN', 'AUX', 'UNK', 'UNK', 'UNK', 'AUX', 'PRON', 'UNK', 'VERB', 'AUX']\n",
      "Accuracy: 68.42%\n"
     ]
    }
   ],
   "source": [
    "# test_data = [\n",
    "#     (\"હું શાળા જાઉં છું\", [\"PRON\",\"NOUN\",\"VERB\",\"AUX\"]),\n",
    "#     (\"તું ઘર આવો\", [\"PRON\",\"NOUN\",\"VERB\"]),\n",
    "# ]\n",
    "\n",
    "test_data = [\n",
    "    (\"હું શાળા જાઉં છું\", [\"PRON\",\"NOUN\",\"VERB\",\"AUX\"]),\n",
    "    (\"તું ઘર આવો\", [\"PRON\",\"NOUN\",\"VERB\"]),\n",
    "    (\"આ મારો મિત્ર છે\", [\"DET\",\"PRON\",\"NOUN\",\"AUX\"]),\n",
    "    (\"બિલાડી ઝડપથી દોડે છે\", [\"NOUN\",\"ADV\",\"VERB\",\"AUX\"]),\n",
    "    (\"હું ભાત ખાઉં છું\", [\"PRON\",\"NOUN\",\"VERB\",\"AUX\"]),\n",
    "]\n",
    "\n",
    "\n",
    "def evaluate(tests):\n",
    "    y_true, y_pred = [], []\n",
    "    for sent, true_tags in tests:\n",
    "        tagged = rule_tag_sentence(sent)\n",
    "        pred = [t for _,t in tagged]\n",
    "        y_true.extend(true_tags)\n",
    "        y_pred.extend(pred)\n",
    "    return y_true, y_pred\n",
    "\n",
    "true_tags, pred_tags = evaluate(test_data)\n",
    "\n",
    "print(\"True:\", true_tags)\n",
    "print(\"Pred:\", pred_tags)\n",
    "\n",
    "correct = sum(t1==t2 for t1,t2 in zip(true_tags,pred_tags))\n",
    "acc = correct/len(true_tags)\n",
    "\n",
    "print(f\"Accuracy: {acc*100:.2f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
